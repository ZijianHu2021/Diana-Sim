#!/usr/bin/env python3
"""
Newtonè¿­ä»£æ•°æ®æ”¶é›†å™¨
======================
ä»DC/TRANè§£æä¸­æ”¶é›†Newton-Raphsonè¿­ä»£çš„è¯¦ç»†æ•°æ®ï¼š
- JacobiançŸ©é˜µ
- æ®‹å·®å‘é‡ï¼ˆresidualï¼‰
- æ›´æ–°å‘é‡ï¼ˆdeltaï¼‰
- æ”¶æ•›æŒ‡æ ‡

æ•°æ®ä¿å­˜ä¸ºJSONæ ¼å¼ï¼Œä¾¿äºåç»­åˆ†æå’Œå¯è§†åŒ–
"""

import json
import numpy as np
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple


class NumpyEncoder(json.JSONEncoder):
    """è‡ªå®šä¹‰JSONç¼–ç å™¨ï¼Œç¡®ä¿numpyç±»å‹å’Œæ•°ç»„è¢«æ­£ç¡®åºåˆ—åŒ–ä¸ºé«˜ç²¾åº¦JSON"""
    def default(self, obj):
        # numpy æ•°ç»„è½¬ä¸ºåˆ—è¡¨ï¼ˆJSON æ”¯æŒï¼‰
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        # numpy æ•´æ•°ç±»å‹è½¬ä¸º Python int
        elif isinstance(obj, (np.integer, np.intp)):
            return int(obj)
        # numpy æµ®ç‚¹ç±»å‹è½¬ä¸º Python floatï¼ˆä¿æŒ float64 ç²¾åº¦ï¼‰
        elif isinstance(obj, (np.floating, np.float64, np.float32)):
            return float(obj)
        # numpy bool è½¬ä¸º Python bool
        elif isinstance(obj, np.bool_):
            return bool(obj)
        # å…¶ä»–ç±»å‹è°ƒç”¨çˆ¶ç±»å¤„ç†
        return super().default(obj)



class NewtonIterationData:
    """å•æ­¥Newtonè¿­ä»£çš„æ•°æ®"""
    
    def __init__(self, iteration: int, time: float = None, source_factor: float = None, nlscale: float = None):
        self.iteration = iteration
        self.time = time  # TRANåˆ†ææ—¶çš„ä»¿çœŸæ—¶é—´
        self.source_factor = source_factor  # DCåˆ†ææ—¶çš„æºæ­¥è¿›å› å­ï¼ˆ0.01 ~ 1.0ï¼‰
        self.nlscale = nlscale  # éçº¿æ€§ç¼©æ”¾å› å­ï¼ˆ0.3, 0.6, 1.0ï¼‰
        self.x: Optional[np.ndarray] = None  # å½“å‰èŠ‚ç‚¹ç”µå‹å‘é‡
        self.jacobian: Optional[np.ndarray] = None
        self.residual: Optional[np.ndarray] = None
        self.delta_x: Optional[np.ndarray] = None
        self.node_names: List[str] = []
        self.max_residual = None
        self.max_delta = None
        self.l2_residual = None
        self.l2_delta = None
        self.convergence_metrics: Dict[str, float] = {}
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå¯JSONåºåˆ—åŒ–çš„å­—å…¸"""
        return {
            'iteration': self.iteration,
            'time': self.time,
            'source_factor': float(self.source_factor) if self.source_factor is not None else None,
            'nlscale': float(self.nlscale) if self.nlscale is not None else None,
            'x': self.x.tolist() if self.x is not None else None,
            'jacobian': self.jacobian.tolist() if self.jacobian is not None else None,
            'jacobian_shape': self.jacobian.shape if self.jacobian is not None else None,
            'jacobian_condition_number': float(np.linalg.cond(self.jacobian)) 
                                         if self.jacobian is not None and self.jacobian.shape[0] > 0 
                                         else None,
            'residual': self.residual.tolist() if self.residual is not None else None,
            'delta_x': self.delta_x.tolist() if self.delta_x is not None else None,
            'node_names': self.node_names,
            'max_residual': float(self.max_residual) if self.max_residual is not None else None,
            'max_delta': float(self.max_delta) if self.max_delta is not None else None,
            'l2_residual': float(self.l2_residual) if self.l2_residual is not None else None,
            'l2_delta': float(self.l2_delta) if self.l2_delta is not None else None,
            'convergence_metrics': {k: float(v) for k, v in self.convergence_metrics.items()},
        }


class NewtonDataCollector:
    """æ”¶é›†å¤šæ­¥Newtonè¿­ä»£æ•°æ®"""
    
    def __init__(self, analysis_type: str = "DC", verbose: bool = False):
        """
        Args:
            analysis_type: "DC" æˆ– "TRAN"
            verbose: æ˜¯å¦æ‰“å°è°ƒè¯•ä¿¡æ¯
        """
        self.analysis_type = analysis_type
        self.verbose = verbose
        self.iterations: List[NewtonIterationData] = []
        self.metadata: Dict[str, Any] = {
            'analysis_type': analysis_type,
            'timestamp': datetime.now().isoformat(),
            'total_iterations': 0,
            'converged': False,
            'convergence_reason': None,
        }
    
    def add_iteration(self, data: NewtonIterationData):
        """æ·»åŠ ä¸€æ­¥è¿­ä»£æ•°æ®"""
        self.iterations.append(data)
        if self.verbose:
            print(f"  Iter {data.iteration}: max_res={data.max_residual:.3e}, "
                  f"max_delta={data.max_delta:.3e}")
    
    def add_jacobian(self, J: np.ndarray, node_names: List[str]):
        """ä¸ºæœ€åä¸€æ­¥è¿­ä»£æ·»åŠ JacobiançŸ©é˜µ"""
        if self.iterations:
            self.iterations[-1].jacobian = J.copy()
            self.iterations[-1].node_names = node_names.copy()
    
    def add_residual(self, residual: np.ndarray):
        """ä¸ºæœ€åä¸€æ­¥è¿­ä»£æ·»åŠ æ®‹å·®"""
        if self.iterations:
            self.iterations[-1].residual = residual.copy()
            self.iterations[-1].max_residual = np.max(np.abs(residual))
            self.iterations[-1].l2_residual = np.linalg.norm(residual)
    
    def add_delta(self, delta_x: np.ndarray):
        """ä¸ºæœ€åä¸€æ­¥è¿­ä»£æ·»åŠ æ›´æ–°å‘é‡"""
        if self.iterations:
            self.iterations[-1].delta_x = delta_x.copy()
            self.iterations[-1].max_delta = np.max(np.abs(delta_x))
            self.iterations[-1].l2_delta = np.linalg.norm(delta_x)
    
    def set_convergence(self, converged: bool, reason: str = ""):
        """è®¾ç½®æ”¶æ•›çŠ¶æ€"""
        self.metadata['converged'] = converged
        self.metadata['convergence_reason'] = reason
        self.metadata['total_iterations'] = len(self.iterations)
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'metadata': self.metadata,
            'iterations': [it.to_dict() for it in self.iterations],
        }
    
    def save_to_json(self, filepath: str, compact: bool = False):
        """ä¿å­˜åˆ°JSONæ–‡ä»¶
        
        Args:
            filepath: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            compact: å¦‚æœTrueï¼Œä¸ä¿å­˜å®Œæ•´çš„Jacobianå’Œæ®‹å·®ï¼ˆèŠ‚çœç©ºé—´ï¼‰
        """
        data = self.to_dict()
        
        if compact:
            # ç§»é™¤å¤§å‹çŸ©é˜µä»¥å‡å°‘æ–‡ä»¶å¤§å°
            for it in data['iterations']:
                it['jacobian'] = None
                it['residual'] = None
                it['delta_x'] = None
        
        Path(filepath).parent.mkdir(parents=True, exist_ok=True)
        
    def save_to_json(self, filepath: str, compact: bool = False):
        """ä¿å­˜åˆ°JSONæ–‡ä»¶ï¼Œä¿æŒé«˜ç²¾åº¦
        
        Args:
            filepath: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            compact: å¦‚æœTrueï¼Œä¸ä¿å­˜å®Œæ•´çš„Jacobianå’Œæ®‹å·®ï¼ˆèŠ‚çœç©ºé—´ï¼‰
        """
        data = self.to_dict()
        
        if compact:
            # ç§»é™¤å¤§å‹çŸ©é˜µä»¥å‡å°‘æ–‡ä»¶å¤§å°
            for it in data['iterations']:
                it['jacobian'] = None
                it['residual'] = None
                it['delta_x'] = None
        
        Path(filepath).parent.mkdir(parents=True, exist_ok=True)
        
        # ä½¿ç”¨è‡ªå®šä¹‰ç¼–ç å™¨å¹¶ç¦ç”¨ allow_nan ä»¥ä¿è¯ç²¾åº¦
        # ä½¿ç”¨è¾ƒå°çš„ separators å‡å°æ–‡ä»¶å¤§å°ï¼Œä½†ä¿ç•™ç²¾åº¦
        with open(filepath, 'w') as f:
            # indent=2 ç”¨äºå¯è¯»æ€§ï¼Œå…è®¸ NaN/Infinity ä»¥ä¿ç•™åŸå§‹å€¼
            json.dump(data, f, indent=2, cls=NumpyEncoder, 
                     separators=(',', ': '), ensure_ascii=True)
        
        if self.verbose:
            print(f"\nâœ… Newton data saved to: {filepath}")
            print(f"   File size: {Path(filepath).stat().st_size / 1024:.1f} KB")
            print(f"   Precision: Full float64 precision retained")
        
        if self.verbose:
            print(f"\nâœ… Newton data saved to: {filepath}")
            print(f"   File size: {Path(filepath).stat().st_size / 1024:.1f} KB")


class NewtonDataAnalyzer:
    """åˆ†æNewtonè¿­ä»£æ•°æ®"""
    
    def __init__(self, json_file: str):
        """ä»JSONæ–‡ä»¶åŠ è½½æ•°æ®"""
        with open(json_file, 'r') as f:
            self.data = json.load(f)
        self.metadata = self.data['metadata']
        self.iterations = self.data['iterations']
    
    def print_summary(self):
        """æ‰“å°æ‘˜è¦"""
        print("\n" + "="*80)
        print("ğŸ“Š Newton Iteration Analysis Summary")
        print("="*80)
        
        print(f"\nAnalysis Type: {self.metadata['analysis_type']}")
        print(f"Converged: {self.metadata['converged']}")
        print(f"Total Iterations: {self.metadata['total_iterations']}")
        print(f"Convergence Reason: {self.metadata['convergence_reason']}")
        
        if not self.iterations:
            print("\nâš ï¸  No iteration data available")
            return
        
        print(f"\n{'Iter':<6} {'Max Res':<12} {'Max Î”x':<12} {'L2 Res':<12} {'L2 Î”x':<12} {'Cond Num':<12}")
        print("-" * 80)
        
        for it in self.iterations:
            max_res = it['max_residual'] or 0.0
            max_delta = it['max_delta'] or 0.0
            l2_res = it['l2_residual'] or 0.0
            l2_delta = it['l2_delta'] or 0.0
            cond_num = it['jacobian_condition_number'] or 0.0
            
            print(f"{it['iteration']:<6} {max_res:<12.3e} {max_delta:<12.3e} "
                  f"{l2_res:<12.3e} {l2_delta:<12.3e} {cond_num:<12.3e}")
        
        # æ”¶æ•›è¶‹åŠ¿åˆ†æ
        print(f"\n{'='*80}")
        print("ğŸ“ˆ Convergence Trend Analysis")
        print("="*80)
        
        max_residuals = [it['max_residual'] for it in self.iterations if it['max_residual'] is not None]
        max_deltas = [it['max_delta'] for it in self.iterations if it['max_delta'] is not None]
        
        if max_residuals:
            print(f"\nMax Residual Trend:")
            print(f"  First: {max_residuals[0]:.3e}")
            print(f"  Last:  {max_residuals[-1]:.3e}")
            print(f"  Reduction: {max_residuals[0]/max_residuals[-1]:.3e}x" 
                  if max_residuals[-1] > 0 else "  Reduction: infinite")
            
            # è®¡ç®—å¹³å‡å‡å°‘ç‡
            reductions = []
            for i in range(1, len(max_residuals)):
                if max_residuals[i-1] > 0:
                    reductions.append(max_residuals[i-1] / max_residuals[i])
            
            if reductions:
                print(f"  Avg reduction per iter: {np.mean(reductions):.3f}x")
        
        if max_deltas:
            print(f"\nMax Delta Trend:")
            print(f"  First: {max_deltas[0]:.3e}")
            print(f"  Last:  {max_deltas[-1]:.3e}")
    
    def export_convergence_csv(self, filepath: str):
        """å¯¼å‡ºæ”¶æ•›æ•°æ®ä¸ºCSV"""
        import csv
        
        with open(filepath, 'w', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(['Iteration', 'Max_Residual', 'Max_Delta', 'L2_Residual', 'L2_Delta', 'Jacobian_Condition_Num'])
            
            for it in self.iterations:
                writer.writerow([
                    it['iteration'],
                    it['max_residual'] or '',
                    it['max_delta'] or '',
                    it['l2_residual'] or '',
                    it['l2_delta'] or '',
                    it['jacobian_condition_number'] or '',
                ])
        
        print(f"\nâœ… Convergence data exported to: {filepath}")
    
    def print_jacobian_info(self, iteration: int = None):
        """æ‰“å°æŒ‡å®šè¿­ä»£æ­¥çš„JacobiançŸ©é˜µè¯¦ç»†ä¿¡æ¯
        
        Args:
            iteration: è¿­ä»£æ­¥æ•°ï¼ˆå¦‚æœä¸ºNoneï¼Œæ‰“å°æœ€åä¸€æ­¥ï¼‰
        """
        if iteration is None:
            it = self.iterations[-1] if self.iterations else None
        else:
            it = next((i for i in self.iterations if i['iteration'] == iteration), None)
        
        if it is None:
            print("âš ï¸  Iteration not found")
            return
        
        print(f"\n{'='*80}")
        print(f"ğŸ“Š Jacobian Matrix Analysis - Iteration {it['iteration']}")
        print(f"{'='*80}\n")
        
        if it['jacobian'] is not None:
            print(f"Shape: {it['jacobian_shape']}")
            print(f"Condition Number: {it['jacobian_condition_number']:.3e}")
            print(f"\nMatrix:")
            # æ˜¾ç¤ºçŸ©é˜µï¼Œæ¯è¡Œé™åˆ¶å®½åº¦
            jacobian = np.array(it['jacobian']) if isinstance(it['jacobian'], list) else it['jacobian']
            with np.printoptions(precision=3, suppress=True, threshold=50, edgeitems=3):
                print(jacobian)
        else:
            print("âš ï¸  Jacobian matrix not available in this iteration")
    
    def print_residual_info(self, iteration: int = None):
        """æ‰“å°æŒ‡å®šè¿­ä»£æ­¥çš„æ®‹å·®å‘é‡è¯¦ç»†ä¿¡æ¯
        
        Args:
            iteration: è¿­ä»£æ­¥æ•°ï¼ˆå¦‚æœä¸ºNoneï¼Œæ‰“å°æœ€åä¸€æ­¥ï¼‰
        """
        if iteration is None:
            it = self.iterations[-1] if self.iterations else None
        else:
            it = next((i for i in self.iterations if i['iteration'] == iteration), None)
        
        if it is None:
            print("âš ï¸  Iteration not found")
            return
        
        print(f"\n{'='*80}")
        print(f"ğŸ“Š Residual Vector Analysis - Iteration {it['iteration']}")
        print(f"{'='*80}\n")
        
        if it['residual'] is not None:
            residual = np.array(it['residual'])
            node_names = it['node_names']
            
            print(f"Vector Size: {len(residual)}")
            print(f"Max Residual: {it['max_residual']:.3e}")
            print(f"L2 Norm: {it['l2_residual']:.3e}")
            print(f"\nDetailed Residual by Node:")
            print(f"{'Node':<15s} {'Index':<6s} {'Residual Value':<15s} {'Abs Value':<15s}")
            print("-" * 60)
            
            for idx, (name, val) in enumerate(zip(node_names, residual)):
                print(f"{name:<15s} {idx:<6d} {val:+.6e}  {abs(val):.6e}")
        else:
            print("âš ï¸  Residual vector not available in this iteration")
    
    def print_iteration_detail(self, iteration: int = None):
        """æ‰“å°ä¸€ä¸ªè¿­ä»£æ­¥çš„å®Œæ•´è¯¦ç»†ä¿¡æ¯
        
        Args:
            iteration: è¿­ä»£æ­¥æ•°ï¼ˆå¦‚æœä¸ºNoneï¼Œæ‰“å°æœ€åä¸€æ­¥ï¼‰
        """
        if iteration is None:
            it = self.iterations[-1] if self.iterations else None
        else:
            it = next((i for i in self.iterations if i['iteration'] == iteration), None)
        
        if it is None:
            print("âš ï¸  Iteration not found")
            return
        
        print(f"\n{'='*80}")
        print(f"ğŸ” Complete Iteration Details - Iteration {it['iteration']}")
        print(f"{'='*80}\n")
        
        print(f"Time: {it['time']}")
        print(f"Jacobian Shape: {it['jacobian_shape']}")
        print(f"Jacobian Condition Number: {it['jacobian_condition_number']:.3e}")
        print(f"\nConvergence Metrics:")
        print(f"  Max Residual: {it['max_residual']:.3e}")
        print(f"  Max Delta:    {it['max_delta']:.3e}")
        print(f"  L2 Residual:  {it['l2_residual']:.3e}")
        print(f"  L2 Delta:     {it['l2_delta']:.3e}")
        
        if it['convergence_metrics']:
            print(f"\nAdditional Metrics:")
            for key, val in it['convergence_metrics'].items():
                print(f"  {key}: {val:.3e}")
        
        # æ˜¾ç¤ºresidualå‘é‡
        self.print_residual_info(iteration)
        
        # æ˜¾ç¤ºJacobiançŸ©é˜µï¼ˆä»…æ˜¾ç¤ºç¨€ç–çŸ©é˜µç»Ÿè®¡ï¼‰
        if it['jacobian'] is not None:
            jacobian = np.array(it['jacobian']) if isinstance(it['jacobian'], list) else it['jacobian']
            sparsity = 1.0 - (np.count_nonzero(jacobian) / jacobian.size)
            print(f"\nJacobian Sparsity: {sparsity*100:.1f}%")
            print(f"Non-zero Elements: {np.count_nonzero(jacobian)} / {jacobian.size}")
    
    def export_jacobian_matrix(self, iteration: int, filepath: str):
        """å¯¼å‡ºæŒ‡å®šè¿­ä»£æ­¥çš„JacobiançŸ©é˜µä¸ºæ–‡æœ¬æ–‡ä»¶
        
        Args:
            iteration: è¿­ä»£æ­¥æ•°
            filepath: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        it = next((i for i in self.iterations if i['iteration'] == iteration), None)
        
        if it is None or it['jacobian'] is None:
            print(f"âš ï¸  Cannot export: Iteration {iteration} or Jacobian not found")
            return
        
        jacobian = np.array(it['jacobian']) if isinstance(it['jacobian'], list) else it['jacobian']
        
        with open(filepath, 'w') as f:
            f.write(f"Jacobian Matrix - Iteration {iteration}\n")
            f.write(f"Shape: {jacobian.shape}\n")
            f.write(f"Condition Number: {it['jacobian_condition_number']:.3e}\n")
            f.write(f"\nMatrix:\n")
            np.savetxt(f, jacobian, fmt='%.6e')
        
        print(f"âœ… Jacobian matrix exported to: {filepath}")
    
    def export_residual_vector(self, iteration: int, filepath: str):
        """å¯¼å‡ºæŒ‡å®šè¿­ä»£æ­¥çš„æ®‹å·®å‘é‡ä¸ºæ–‡æœ¬æ–‡ä»¶
        
        Args:
            iteration: è¿­ä»£æ­¥æ•°
            filepath: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        it = next((i for i in self.iterations if i['iteration'] == iteration), None)
        
        if it is None or it['residual'] is None:
            print(f"âš ï¸  Cannot export: Iteration {iteration} or Residual not found")
            return
        
        residual = np.array(it['residual'])
        node_names = it['node_names']
        
        with open(filepath, 'w') as f:
            f.write(f"Residual Vector - Iteration {iteration}\n")
            f.write(f"Size: {len(residual)}\n")
            f.write(f"Max Residual: {it['max_residual']:.3e}\n")
            f.write(f"L2 Norm: {it['l2_residual']:.3e}\n")
            f.write(f"\n{'Node':<20s} {'Index':<8s} {'Residual Value':<20s} {'Abs Value':<20s}\n")
            f.write("-" * 70 + "\n")
            
            for idx, (name, val) in enumerate(zip(node_names, residual)):
                f.write(f"{name:<20s} {idx:<8d} {val:+.12e}  {abs(val):.12e}\n")
        
        print(f"âœ… Residual vector exported to: {filepath}")
    
    def generate_iteration_tracking_log(self, filepath: str = None) -> str:
        """ç”Ÿæˆè¯¦ç»†çš„è¿­ä»£è¿½è¸ªæ—¥å¿—ï¼Œæ˜¾ç¤ºæ¯æ¬¡è¿­ä»£ä¸­èŠ‚ç‚¹ç”µå‹çš„å˜åŒ–"""
        
        log_lines = []
        log_lines.append("=" * 100)
        log_lines.append("ğŸ“Š Newtonè¿­ä»£è¯¦ç»†è¿½è¸ªæ—¥å¿— - èŠ‚ç‚¹ç”µå‹å˜åŒ–è¿‡ç¨‹")
        log_lines.append("=" * 100)
        log_lines.append("")
        
        # æ·»åŠ åˆå§‹ä¿¡æ¯
        log_lines.append("åˆ†æç±»å‹: " + self.metadata.get('analysis_type', 'N/A'))
        log_lines.append("æ€»è¿­ä»£æ¬¡æ•°: " + str(self.metadata.get('total_iterations', 0)))
        log_lines.append("æ”¶æ•›çŠ¶æ€: " + str(self.metadata.get('converged', False)))
        log_lines.append("")
        
        if not self.iterations:
            log_lines.append("âš ï¸  æ²¡æœ‰è¿­ä»£æ•°æ®")
            log_content = "\n".join(log_lines)
            if filepath:
                Path(filepath).parent.mkdir(parents=True, exist_ok=True)
                with open(filepath, 'w', encoding='utf-8') as f:
                    f.write(log_content)
            return log_content
        
        # è·å–åˆå§‹å€¼ï¼ˆç¬¬ä¸€æ¬¡è¿­ä»£çš„xå‘é‡ï¼‰
        first_x = self.iterations[0].get('x')
        node_names = self.iterations[0].get('node_names', [])
        
        if not first_x or not node_names:
            log_lines.append("âš ï¸  ç¼ºå°‘åˆå§‹èŠ‚ç‚¹å€¼æˆ–èŠ‚ç‚¹åç§°ä¿¡æ¯")
            log_content = "\n".join(log_lines)
            if filepath:
                Path(filepath).parent.mkdir(parents=True, exist_ok=True)
                with open(filepath, 'w', encoding='utf-8') as f:
                    f.write(log_content)
            return log_content
        
        # æŸ¥æ‰¾åˆå§‹çŠ¶æ€ï¼ˆiteration=-1ï¼‰æˆ–ä½¿ç”¨ç¬¬ä¸€æ¬¡è¿­ä»£ä½œä¸ºåˆå§‹å€¼
        init_x = None
        start_idx = 0
        
        if self.iterations[0].get('iteration', 0) == -1:
            # æ‰¾åˆ°äº†åˆå§‹çŠ¶æ€è®°å½•
            init_x = np.array(first_x) if isinstance(first_x, list) else first_x
            start_idx = 1  # ä»ç¬¬äºŒä¸ªè®°å½•å¼€å§‹å¤„ç†ï¼ˆç¬¬ä¸€ä¸ªæ˜¯åˆå§‹çŠ¶æ€ï¼‰
            log_lines.append("ğŸ¯ åˆå§‹èŠ‚ç‚¹ç”µå‹ï¼ˆè¿­ä»£å¼€å§‹å‰ï¼‰:")
        else:
            # æ²¡æœ‰åˆå§‹çŠ¶æ€è®°å½•ï¼Œä½¿ç”¨ç¬¬ä¸€æ¬¡è¿­ä»£çš„xä½œä¸ºå‚è€ƒ
            init_x = np.array(first_x) if isinstance(first_x, list) else first_x
            start_idx = 0
            log_lines.append("ğŸ¯ ç¬¬ä¸€æ¬¡è¿­ä»£çš„èŠ‚ç‚¹ç”µå‹:")
        
        log_lines.append("-" * 100)
        log_lines.append(f"{'èŠ‚ç‚¹åç§°':<20} {'ç”µå‹å€¼ (V)':<15} {'å˜åŒ–é‡ (V)':<15} {'è¯´æ˜':<50}")
        log_lines.append("-" * 100)
        for i, (node_name, v_init) in enumerate(zip(node_names, init_x)):
            log_lines.append(f"{node_name:<20} {v_init:>14.10f} {0.0:>14.10f} {'åˆå§‹çŒœæµ‹å€¼':<50}")
        log_lines.append("")
        
        # éå†æ¯ä¸ªè¿­ä»£æ­¥éª¤ï¼ˆä»start_idxå¼€å§‹ï¼Œè·³è¿‡åˆå§‹çŠ¶æ€è®°å½•ï¼‰
        # æ³¨æ„ï¼šç°åœ¨JSONä¸­çš„xæ˜¯æ›´æ–°åçš„å€¼
        prev_x = init_x.copy()
        
        for iter_idx in range(start_idx, len(self.iterations)):
            iteration = self.iterations[iter_idx]
            iter_num = iteration.get('iteration', iter_idx)
            source_factor = iteration.get('source_factor', 'N/A')
            nlscale = iteration.get('nlscale', 'N/A')
            max_res = iteration.get('max_residual', 0)
            max_delta = iteration.get('max_delta', 0)
            l2_res = iteration.get('l2_residual', 0)
            l2_delta = iteration.get('l2_delta', 0)
            
            # å½“å‰è¿­ä»£çš„xå€¼ï¼ˆè¿™æ˜¯æ›´æ–°åçš„å€¼ï¼‰
            current_x = iteration.get('x')
            residual = iteration.get('residual', [])
            delta_x_vec = iteration.get('delta_x', [])
            
            if current_x is None:
                continue
            
            current_x = np.array(current_x) if isinstance(current_x, list) else current_x
            residual = np.array(residual) if isinstance(residual, list) else residual
            delta_x_vec = np.array(delta_x_vec) if isinstance(delta_x_vec, list) else delta_x_vec
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°çš„source_factoræ­¥éª¤çš„ç¬¬ä¸€æ¬¡è¿­ä»£
            # å¦‚æœæ˜¯ï¼Œéœ€è¦ä»ä¸Šä¸€æ­¥çš„æœ€åxå€¼æˆ–å½“å‰xè·å–æ—§å€¼
            if iter_idx > 0:
                prev_iter = self.iterations[iter_idx - 1]
                prev_sf = prev_iter.get('source_factor', None)
                curr_sf = source_factor
                
                # å¦‚æœsource_factoræ”¹å˜äº†ï¼Œè¯´æ˜å¼€å§‹æ–°çš„steppingé˜¶æ®µ
                # æ­¤æ—¶"æ—§å€¼"åº”è¯¥æ˜¯ä¸Šä¸€é˜¶æ®µçš„æœ€ç»ˆå€¼ï¼ˆå³ä¸Šä¸€æ¬¡è¿­ä»£çš„xï¼‰
                if prev_sf != curr_sf and prev_sf is not None:
                    # Source factorå˜åŒ–ï¼Œprev_xå·²ç»æ˜¯æ­£ç¡®çš„ï¼ˆä¸Šä¸€é˜¶æ®µçš„æœ€ç»ˆå€¼ï¼‰
                    pass
            
            log_lines.append("=" * 100)
            log_lines.append(f"ğŸ“ è¿­ä»£ #{iter_num} (Source Factor: {source_factor}, NL Scale: {nlscale})")
            log_lines.append("=" * 100)
            
            # æ”¶æ•›æŒ‡æ ‡
            log_lines.append(f"æ”¶æ•›æŒ‡æ ‡:")
            log_lines.append(f"  Max Residual: {max_res:.3e} V/A")
            log_lines.append(f"  Max Î”x:       {max_delta:.3e} V/A")
            log_lines.append(f"  L2 Residual:  {l2_res:.3e}")
            log_lines.append(f"  L2 Î”x:        {l2_delta:.3e}")
            log_lines.append("")
            
            # è¯¦ç»†çš„èŠ‚ç‚¹å˜åŒ–
            log_lines.append(f"{'èŠ‚ç‚¹åç§°':<20} {'æ®‹å·®':<15} {'æ›´æ–°é‡':<15} {'è¿­ä»£å‰ (V)':<15} {'è¿­ä»£å (V)':<15} {'å®é™…å˜åŒ–':<15}")
            log_lines.append("-" * 100)
            
            for i, node_name in enumerate(node_names):
                if i < len(residual):
                    res = residual[i]
                else:
                    res = 0.0
                
                if i < len(delta_x_vec):
                    delta = delta_x_vec[i]
                else:
                    delta = 0.0
                
                # æ—§å€¼ = å‰ä¸€æ¬¡è¿­ä»£çš„ç»“æœ
                old_val = prev_x[i]
                # æ–°å€¼ = å½“å‰è¿­ä»£çš„ç»“æœ
                new_val = current_x[i]
                # å®é™…å˜åŒ–ï¼ˆåŒ…å«äº†dampingæ•ˆæœï¼‰
                change = new_val - old_val
                
                # æ ¼å¼åŒ–è¾“å‡º
                log_lines.append(
                    f"{node_name:<20} {res:>14.3e} {delta:>14.3e} {old_val:>14.10f} {new_val:>14.10f} {change:>14.10f}"
                )
            
            log_lines.append("")
            
            # æ›´æ–°prev_xä¸ºå½“å‰è¿­ä»£çš„ç»“æœï¼Œä¾›ä¸‹æ¬¡ä½¿ç”¨
            prev_x = current_x.copy()
        
        # æ˜¾ç¤ºæœ€ç»ˆå€¼
        log_lines.append("=" * 100)
        log_lines.append("âœ… æœ€ç»ˆæ”¶æ•›èŠ‚ç‚¹ç”µå‹:")
        log_lines.append("-" * 100)
        log_lines.append(f"{'èŠ‚ç‚¹åç§°':<20} {'æœ€ç»ˆå€¼ (V)':<15} {'åˆå§‹å€¼ (V)':<15} {'æ€»å˜åŒ– (V)':<15}")
        log_lines.append("-" * 100)
        
        final_x = np.array(self.iterations[-1].get('x', first_x)) if self.iterations else first_x
        for node_name, v_final, v_init in zip(node_names, final_x, first_x):
            total_change = v_final - v_init
            log_lines.append(f"{node_name:<20} {v_final:>14.10f} {v_init:>14.10f} {total_change:>14.10f}")
        
        log_lines.append("")
        log_lines.append("=" * 100)
        
        log_content = "\n".join(log_lines)
        
        if filepath:
            Path(filepath).parent.mkdir(parents=True, exist_ok=True)
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(log_content)
            print(f"\nâœ… è¿­ä»£è¿½è¸ªæ—¥å¿—å·²ä¿å­˜åˆ°: {filepath}")
        
        return log_content
    
    def plot_convergence(self, filepath: str = None):
        """ç»˜åˆ¶æ”¶æ•›æ›²çº¿"""
        try:
            import matplotlib.pyplot as plt
        except ImportError:
            print("âš ï¸  matplotlib not available, skipping plot")
            return
        
        iterations = [it['iteration'] for it in self.iterations]
        max_residuals = [it['max_residual'] or 0 for it in self.iterations]
        max_deltas = [it['max_delta'] or 0 for it in self.iterations]
        
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))
        
        # Max residual
        ax1.semilogy(iterations, max_residuals, 'o-', linewidth=2, markersize=6)
        ax1.set_xlabel('Iteration')
        ax1.set_ylabel('Max Residual (V or A)')
        ax1.set_title(f'{self.metadata["analysis_type"]} Analysis - Max Residual')
        ax1.grid(True, which='both', alpha=0.3)
        
        # Max delta
        ax2.semilogy(iterations, max_deltas, 's-', linewidth=2, markersize=6, color='orange')
        ax2.set_xlabel('Iteration')
        ax2.set_ylabel('Max Î”x (V or A)')
        ax2.set_title(f'{self.metadata["analysis_type"]} Analysis - Max Delta')
        ax2.grid(True, which='both', alpha=0.3)
        
        plt.tight_layout()
        
        if filepath:
            Path(filepath).parent.mkdir(parents=True, exist_ok=True)
            plt.savefig(filepath, dpi=150)
            print(f"\nâœ… Convergence plot saved to: {filepath}")
        else:
            plt.show()


if __name__ == "__main__":
    # æµ‹è¯•ç¤ºä¾‹
    collector = NewtonDataCollector("DC", verbose=True)
    
    # æ¨¡æ‹Ÿ3æ­¥è¿­ä»£
    for i in range(3):
        data = NewtonIterationData(i + 1)
        data.residual = np.random.randn(4) * 10**(-(i+1))
        data.delta_x = np.random.randn(4) * 10**(-(i+1))
        data.jacobian = np.random.randn(4, 4)
        data.node_names = ['VDD', 'VOUT', 'VSS', 'GND']
        data.max_residual = np.max(np.abs(data.residual))
        data.max_delta = np.max(np.abs(data.delta_x))
        data.l2_residual = np.linalg.norm(data.residual)
        data.l2_delta = np.linalg.norm(data.delta_x)
        
        collector.add_iteration(data)
    
    collector.set_convergence(True, "Converged to tolerance")
    
    # ä¿å­˜
    output_file = "/tmp/test_newton_data.json"
    collector.save_to_json(output_file)
    
    # åˆ†æ
    analyzer = NewtonDataAnalyzer(output_file)
    analyzer.print_summary()
