#!/usr/bin/env python3
"""
GNNæ•°æ®é›†åŠ è½½ - å®Œå…¨æŒ‰ç…§è§„èŒƒä½¿ç”¨æ•°æ®

ğŸ“‹ æ•°æ®ä½¿ç”¨è§„èŒƒ:
  1. node_features.npy ä½œä¸ºGNNè¾“å…¥ (å½¢çŠ¶: 10, 3)
     - [0]: ç”µå‹V (çº¦0-3V)
     - [1]: æ®‹å·®f (çº¦1e-15åˆ°1e-3)
     - [2]: èŠ‚ç‚¹ç±»å‹ (0-5)
  
  2. edge_index.npy + edge_attr.npy æ„å»ºå›¾ç»“æ„
     - edge_index: (2, E) - è¾¹çš„è¿æ¥å…³ç³»
     - edge_attr: (E, 1) - è¾¹çš„å±æ€§ï¼ˆåŠ è½½ä½†ä¸ç”¨äºæ ‡å‡†GCNï¼‰
  
  3. actual_changes.npy ä½œä¸ºè®­ç»ƒæ ‡ç­¾ (å½¢çŠ¶: 55, 10)
     - æ ‡ç­¾å®šä¹‰: æœ€ç»ˆæ”¶æ•›å€¼(V) - æœ¬æ¬¡è¿­ä»£åå€¼(V)
     - actual_changes[i] å¯¹åº” iteration_i/ ç›®å½•çš„æ ‡ç­¾

ç‰¹å¾å½’ä¸€åŒ–:
  - ä½¿ç”¨StandardScalerå¯¹æ‰€æœ‰èŠ‚ç‚¹ç‰¹å¾è¿›è¡Œå½’ä¸€åŒ–
  - åœ¨è®­ç»ƒé›†ä¸Šæ‹Ÿåˆscalerï¼Œç„¶ååº”ç”¨åˆ°æ‰€æœ‰æ•°æ®
  - è§£å†³ç‰¹å¾é‡çº²ä¸åŒ¹é…é—®é¢˜ (V vs f é‡çº§å·®å¼‚å¤§)
"""
import json
from pathlib import Path
from typing import List, Tuple, Optional

import numpy as np
import torch
from torch_geometric.data import Data
from sklearn.preprocessing import StandardScaler


def _sorted_iteration_dirs(numpy_dir: Path) -> List[Path]:
    """
    è·å–æ’åºåçš„è¿­ä»£ç›®å½•åˆ—è¡¨
    
    Args:
        numpy_dir: numpyç›®å½•è·¯å¾„ (e.g., /path/to/gnn_data/numpy)
    
    Returns:
        æŒ‰è¿­ä»£ç¼–å·æ’åºçš„ç›®å½•åˆ—è¡¨ [iteration_0, iteration_1, ..., iteration_54]
    """
    iteration_dirs = [d for d in numpy_dir.iterdir() if d.is_dir() and d.name.startswith("iteration_")]
    iteration_dirs.sort(key=lambda p: int(p.name.split("_")[-1]))
    return iteration_dirs


def load_actual_changes(data_root: Path) -> np.ndarray:
    """
    åŠ è½½æ ‡ç­¾æ•°æ®
    
    Args:
        data_root: æ•°æ®æ ¹ç›®å½•
    
    Returns:
        actual_changes: (55, 10) æ•°ç»„
          - 55: è¿­ä»£æ•°
          - 10: æ¯ä¸ªè¿­ä»£çš„èŠ‚ç‚¹æ•°
          - å€¼: æœ€ç»ˆæ”¶æ•›å€¼(V) - æœ¬æ¬¡è¿­ä»£åå€¼(V)
    """
    changes_path = data_root / "actual_changes.npy"
    if not changes_path.exists():
        raise FileNotFoundError(f"æœªæ‰¾åˆ°actual_changes.npy: {changes_path}")
    return np.load(changes_path)


def load_train_val_split(data_root: Path) -> Tuple[List[int], List[int]]:
    """
    åŠ è½½é¢„å®šä¹‰çš„è®­ç»ƒ/éªŒè¯é›†åˆ†å‰²
    
    Args:
        data_root: æ•°æ®æ ¹ç›®å½•
    
    Returns:
        (train_indices, val_indices) - è‹¥æ–‡ä»¶ä¸å­˜åœ¨è¿”å› ([], [])
    """
    split_path = data_root / "train_val_split.json"
    if not split_path.exists():
        return [], []
    with open(split_path, "r") as f:
        split = json.load(f)
    return split.get("train_indices", []), split.get("val_indices", [])


def build_dataset(data_root: Path, normalize: bool = True, scaler: Optional[StandardScaler] = None) -> Tuple[List[Data], Optional[StandardScaler]]:
    """
    æ„å»ºPyTorch Geometricæ•°æ®é›†ï¼Œæ”¯æŒç‰¹å¾å½’ä¸€åŒ–
    
    ä»numpyæ–‡ä»¶åŠ è½½å›¾æ•°æ®ï¼Œæ„é€ PyTorch Geometricçš„Dataå¯¹è±¡åˆ—è¡¨
    
    å‚æ•°:
        data_root: æ•°æ®æ ¹ç›®å½• (åŒ…å«numpy/å’Œactual_changes.npy)
        normalize: æ˜¯å¦å¯¹èŠ‚ç‚¹ç‰¹å¾è¿›è¡Œå½’ä¸€åŒ– (é»˜è®¤True)
        scaler: å·²æ‹Ÿåˆçš„StandardScalerå¯¹è±¡
                è‹¥ä¸ºNoneï¼Œåˆ™å¯¹æ•°æ®è¿›è¡Œæ‹Ÿåˆï¼ˆè®­ç»ƒé›†æ¨¡å¼ï¼‰
                è‹¥ä¸ä¸ºNoneï¼Œåˆ™ä»…ä½¿ç”¨è¯¥scalerè¿›è¡Œå˜æ¢ï¼ˆæµ‹è¯•é›†æ¨¡å¼ï¼‰
    
    è¿”å›:
        (data_list, scaler)
        - data_list: List[Data], é•¿åº¦ä¸º55 (55ä¸ªè¿­ä»£)
        - scaler: ä½¿ç”¨çš„StandardScalerå¯¹è±¡ï¼ˆè‹¥normalize=Trueï¼‰æˆ–None
    
    æ•°æ®ç»“æ„ (æ¯ä¸ªDataå¯¹è±¡):
        - x: (10, 3) èŠ‚ç‚¹ç‰¹å¾ [ç”µå‹V, æ®‹å·®f, èŠ‚ç‚¹ç±»å‹]
        - edge_index: (2, E) è¾¹è¿æ¥ (é€šå¸¸Eâ‰ˆ24)
        - edge_attr: (E, 1) è¾¹å±æ€§ï¼ˆåŠ è½½ä½†ä¸å¿…ä½¿ç”¨ï¼‰
        - y: (10, 1) æ ‡ç­¾ - actual_changes[i]
    """
    numpy_dir = data_root / "numpy"
    if not numpy_dir.exists():
        raise FileNotFoundError(f"æœªæ‰¾åˆ°numpyç›®å½•: {numpy_dir}")

    # è·å–æ‰€æœ‰è¿­ä»£ç›®å½•ï¼ˆå·²æ’åºï¼‰
    iteration_dirs = _sorted_iteration_dirs(numpy_dir)
    actual_changes = load_actual_changes(data_root)

    # éªŒè¯æ•°æ®ä¸€è‡´æ€§
    if len(iteration_dirs) != actual_changes.shape[0]:
        raise ValueError(
            f"è¿­ä»£ç›®å½•æ•°é‡({len(iteration_dirs)})ä¸actual_changesè¡Œæ•°({actual_changes.shape[0]})ä¸ä¸€è‡´"
        )

    data_list: List[Data] = []
    
    # æ­¥éª¤1: æ”¶é›†æ‰€æœ‰ç‰¹å¾ç”¨äºå½’ä¸€åŒ–
    all_features = []
    print(f"[æ•°æ®åŠ è½½] è¯»å–{len(iteration_dirs)}ä¸ªè¿­ä»£çš„ç‰¹å¾...")
    for it_dir in iteration_dirs:
        node_features = np.load(it_dir / "node_features.npy").astype(np.float32)
        # node_features å½¢çŠ¶: (10, 3)
        #   ç»´åº¦0: 10ä¸ªèŠ‚ç‚¹
        #   ç»´åº¦1: [V (0-3V), f (1e-15~1e-3), èŠ‚ç‚¹ç±»å‹ (0-5)]
        all_features.append(node_features)
    
    # æ­¥éª¤2: æ‹Ÿåˆæˆ–ä½¿ç”¨å·²æœ‰çš„scalerè¿›è¡Œç‰¹å¾å½’ä¸€åŒ–
    if normalize:
        if scaler is None:
            # è®­ç»ƒæ¨¡å¼: æ‹Ÿåˆscaler
            # å°†æ‰€æœ‰ç‰¹å¾è¿æ¥: (55*10, 3) = (550, 3)
            all_features_concat = np.vstack(all_features)
            scaler = StandardScaler()
            scaler.fit(all_features_concat)
            print(f"[ç‰¹å¾å½’ä¸€åŒ–] å·²æ‹ŸåˆStandardScaler")
            print(f"  - mean: {scaler.mean_}")
            print(f"  - scale (std): {scaler.scale_}")
        
        # å¯¹æ¯ä¸ªè¿­ä»£åº”ç”¨å½’ä¸€åŒ–
        normalized_features = []
        for feat in all_features:
            feat_norm = scaler.transform(feat)  # (10, 3)
            normalized_features.append(feat_norm)
        print(f"[ç‰¹å¾å½’ä¸€åŒ–] å·²åº”ç”¨StandardScaleråˆ°æ‰€æœ‰ç‰¹å¾")
    else:
        normalized_features = all_features
        scaler = None

    # æ­¥éª¤3: æ„é€ Dataå¯¹è±¡åˆ—è¡¨
    print(f"[æ„é€ æ•°æ®é›†] åˆ›å»ºPyTorch Geometric Dataå¯¹è±¡...")
    for idx, it_dir in enumerate(iteration_dirs):
        # åŠ è½½è¾¹ä¿¡æ¯
        edge_index = np.load(it_dir / "edge_index.npy").astype(np.int64)  # (2, E)
        edge_attr = np.load(it_dir / "edge_attr.npy").astype(np.float32)   # (E, 1)

        # åŠ è½½æ ‡ç­¾
        y = actual_changes[idx].astype(np.float32)  # (10,)

        # è½¬æ¢ä¸ºPyTorchå¼ é‡
        x = torch.from_numpy(normalized_features[idx])       # (10, 3)
        edge_index = torch.from_numpy(edge_index)            # (2, E)
        edge_attr = torch.from_numpy(edge_attr)              # (E, 1)
        y = torch.from_numpy(y).view(-1, 1)                  # (10, 1)

        # æ„é€ Dataå¯¹è±¡ï¼ˆä¸ä½¿ç”¨edge_attrï¼Œä½†ä»ç„¶åŠ è½½ä»¥ä¿æŒå…¼å®¹æ€§ï¼‰
        data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)
        data_list.append(data)

    print(f"[å®Œæˆ] å…±{len(data_list)}ä¸ªDataå¯¹è±¡")
    return data_list, scaler
